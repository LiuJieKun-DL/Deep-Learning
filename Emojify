import numpy as np
import cv2

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense,Dropout,Flatten
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import MaxPool2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator


# train_dir = '/Users/liujiekun/Downloads/Emojify/train'
# val_dir = '/Users/liujiekun/Downloads/Emojify/test'
# train_datagen = ImageDataGenerator(rescale=1./255)
# val_datagen = ImageDataGenerator(rescale=1./255)

# train_generator = train_datagen.flow_from_directory(
#     train_dir,
#     target_size=(48,48),
#     batch_size=64,
#     color_mode='grayscale',
#     class_mode='categorical'
# )


# validation_generator = val_datagen.flow_from_directory(
#     val_dir,
#     target_size=(48,48),
#     batch_size=64,
#     color_mode="grayscale",
#     class_mode='categorical'
# )

emotional_model = Sequential()
emotional_model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(48,48,1)))
emotional_model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))
emotional_model.add(MaxPool2D(pool_size=(2,2)))
emotional_model.add(Dropout(0.25))

emotional_model.add(Flatten())
emotional_model.add(Dense(1024,activation='relu'))
emotional_model.add(Dropout(0.5))
emotional_model.add(Dense(7,activation='softmax'))


# emotional_model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.0001,decay=1e-6),metrics=['accuracy'])

# emotional_model_info = emotional_model.fit_generator(
# train_generator,
# steps_per_epoch=28709//64,
# epochs=50,
# validation_data=validation_generator,
# validation_steps=7178//64)

# emotional_model.save_weights('model.h5')

cv2.ocl.setUseOpenCL(False)
emotion_dict = {0:'Angry',1:'Disgusted',2:'Fearful',3:'Happy',4:'Neutral',5:'Sad',6:'Surprised'}

cap = cv2.VideoCapture(0)
while True:
    ret,frame = cap.read()
    if not ret:
        break
    bounding_box =cv2.CascadeClassifier('/Users/liujiekun/Desktop/haarcascade_frontalface_default.xml')
    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)##???
    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor=1.3,minNeighbors=5)
    
    for (x,y,w,h) in num_faces:
        cv2.rectangle(frame,(x,y-50),(x+w,y+h+10),(255,0,0),2)
        roi_gray_frame = gray_frame[y:y+h,x:x+w]
        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame,(48,48)),-1),0)
        emotion_prediction = emotional_model.predict(cropped_img)
        maxindex = int(np.argmax(emotion_prediction))
        cv2.putText(frame,emotion_dict[maxindex],(x+20,y-60),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)
        cv2.imshow('Video',cv2.resize(frame,(1200,860),interpolation=cv2.INTER_CUBIC))
    if cv2.waitKey(1)&0xFF == ord('q'):
        cap.release()
        cv2.destroyAllWindows()
        break

import tkinter as tk
from tkinter import *
import cv2
from PIL import Image,ImageTk
import os



emotional_model = Sequential()
emotional_model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(48,48,1)))
emotional_model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))
emotional_model.add(MaxPool2D(pool_size=(2,2)))
emotional_model.add(Dropout(0.25))

emotional_model.add(Conv2D(128,kernel_size=(3,3),activation='relu')
emotional_model.add(MaxPool2D(pool_size=(2,2)))
emotional_model.add(Conv2D(128,kernel_size=(3,3),activation='relu')
emotional_model.add(MaxPool2D(pool_size=(2,2)))
emotional_model.add(Dropout(0.25))

emotional_model.add(Flatten())
emotional_model.add(Dense(1024,activation='relu'))
emotional_model.add(Dropout(0.5))
emotional_model.add(Dense(7,activation='softmax'))
emotional_model.load_weights('model.h5')

cv2.ocl.setUseOpenCL(False)
                  
emotion_dict = {0: "   Angry   ", 1: "Disgusted", 2: "  Fearful  ", 3: "   Happy   ", 4: "  Neutral  ", 5: "    Sad    ", 6: "Surprised"}

emoji_dist={0:"/Users/liujiekun/Downloads/emoji-creator-project-code/emojis/angry.png",2:"/Users/liujiekun/Downloads/emoji-creator-project-code/emojis/disgusted.png",2:"/Users/liujiekun/Downloads/emoji-creator-project-code/emojis/fearful.png",3:"/Users/liujiekun/Downloads/emoji-creator-project-code/emojis/happy.png",4:"/Users/liujiekun/Downloads/emoji-creator-project-code/emojis/neutral.png",5:"/Users/liujiekun/Downloads/emoji-creator-project-code/emojis/sad.png",6:"/Users/liujiekun/Downloads/emoji-creator-project-code/emojis/surpriced.png"}

global last_frame1                                    
last_frame1 = np.zeros((480, 640, 3), dtype=np.uint8)
global cap1
show_text=[0]

def show_vid():      
    cap1 = cv2.VideoCapture(0)                                 
    if not cap1.isOpened():                             
        print("cant open the camera1")
    flag1, frame1 = cap1.read()
    frame1 = cv2.resize(frame1,(600,500))
    bounding_box = cv2.CascadeClassifier('/Users/liujiekun/Desktop/haarcascade_frontalface_default.xml')
    gray_frame = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)
    for (x, y, w, h) in num_faces:
        cv2.rectangle(frame1, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)
        roi_gray_frame = gray_frame[y:y + h, x:x + w]
        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)
        prediction = emotion_model.predict(cropped_img)
        
        maxindex = int(np.argmax(prediction))
        cv2.putText(frame1, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)
        show_text[0]=maxindex
    if flag1 is None:
        print ("Major error!")
    elif flag1:
        global last_frame1
        last_frame1 = frame1.copy()
        pic = cv2.cvtColor(last_frame1, cv2.COLOR_BGR2RGB)     
        img = Image.fromarray(pic)
        imgtk = ImageTk.PhotoImage(image=img)
        lmain.imgtk = imgtk
        lmain.configure(image=imgtk)
        lmain.after(10, show_vid)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        exit()
def show_vid2():
    frame2=cv2.imread(emoji_dist[show_text[0]])
    pic2=cv2.cvtColor(frame2,cv2.COLOR_BGR2RGB)
    img2=Image.fromarray(frame2)
    imgtk2=ImageTk.PhotoImage(image=img2)
    lmain2.imgtk2=imgtk2
    lmain3.configure(text=emotion_dict[show_text[0]],font=('arial',45,'bold'))
    
    lmain2.configure(image=imgtk2)
    lmain2.after(10, show_vid2)



if __name__ == '__main__':
    root=tk.Tk()   
    img = ImageTk.PhotoImage(Image.open("/Users/liujiekun/Downloads/emoji-creator-project-code/emojis/angry.png"))
    heading = Label(root,image=img,bg='black')
    
    heading.pack() 
    heading2=Label(root,text="Photo to Emoji",pady=20, font=('arial',45,'bold'),bg='black',fg='#CDCDCD')                                 
    
    heading2.pack()
    lmain = tk.Label(master=root,padx=50,bd=10)
    lmain2 = tk.Label(master=root,bd=10)
    lmain3=tk.Label(master=root,bd=10,fg="#CDCDCD",bg='black')
    lmain.pack(side=LEFT)
    lmain.place(x=50,y=250)
    lmain3.pack()
    lmain3.place(x=960,y=250)
    lmain2.pack(side=RIGHT)
    lmain2.place(x=900,y=350)
    
    root.title("Photo To Emoji")            
    root.geometry("1400x900+100+10") 
    root['bg']='black'
    exitbutton = Button(root, text='Quit',fg="red",command=root.destroy,font=('arial',25,'bold')).pack(side = BOTTOM)
    show_vid()
    show_vid2()
    root.mainloop()



